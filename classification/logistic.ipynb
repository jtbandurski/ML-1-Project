{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularised Logistic regression as the benchmark model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score, precision_recall_curve\n",
    "from time import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "already preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10127, 37)\n"
     ]
    }
   ],
   "source": [
    "client_attrition = pd.read_csv('../data/preprocessed/client_attrition_train.csv', sep=\";\")\n",
    "X = client_attrition.drop(\"account_status\",axis=1)\n",
    "y = client_attrition[\"account_status\"]\n",
    "print(X.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train /  test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12345,stratify=y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 183 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "# instantiate the model (using the default parameters)\n",
    "logit = LogisticRegression(penalty='l1',solver='saga',max_iter=1000,random_state=12345,verbose=1)\n",
    "\n",
    "# fit the model with data\n",
    "logit.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.716503414281192"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_true=y_test,y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_education_High School          customer_education_High School\n",
       "customer_civil_status_Divorced          customer_civil_status_Divorced\n",
       "credit_card_classification_Silver    credit_card_classification_Silver\n",
       "customer_salary_range_below 40K        customer_salary_range_below 40K\n",
       "dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Whic coefficients are 0\n",
    "X_train.columns.to_series().loc[(abs(logit.coef_)==0).tolist()[0]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kfold Cross Validation\n",
    "Although there are no hyperparameters to be tuned other than penalty and solvers we want to get more accurate approximation of true balanced accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_rskf(model ,n_splits, n_repeats, seed):\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats,random_state=seed)\n",
    "    cv_results = cross_validate(estimator=model, X=X, y=y, scoring=\"balanced_accuracy\", cv=rskf, verbose=2,\n",
    "                                n_jobs=12, return_train_score=True)\n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df2 = pd.DataFrame(columns=['penalty', 'solver','average train score', 'std of train score','average val score', 'std of val score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>average train score</th>\n",
       "      <th>std of train score</th>\n",
       "      <th>average val score</th>\n",
       "      <th>std of val score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.7398893308</td>\n",
       "      <td>0.0026416632</td>\n",
       "      <td>0.7365539231</td>\n",
       "      <td>0.0168197751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  penalty solver  average train score  std of train score  average val score  \\\n",
       "0      l1   saga         0.7398893308        0.0026416632       0.7365539231   \n",
       "\n",
       "   std of val score  \n",
       "0      0.0168197751  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:    6.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 20.125411987304688 seconds ---\n",
      "average score:  0.7365539231279878 std of score:  0.01681977513915903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:   19.9s finished\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10,random_state=12345)\n",
    "cv_results = cross_validate(estimator=logit, X=X, y=y, scoring=\"balanced_accuracy\", cv=rskf, verbose=2,\n",
    "                                n_jobs=12, return_train_score=True, )\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time() - start_time))     \n",
    "print(\"average score: \", cv_results['test_score'].mean(), \"std of score: \", cv_results['test_score'].std()) \n",
    "# insert to df\n",
    "new_row = {'penalty': logit.get_params()['penalty'], 'solver': logit.get_params()['solver'],\n",
    "                'average train score': cv_results['train_score'].mean(),\"std of train score\": cv_results['train_score'].std(),\n",
    "                'average val score': cv_results['test_score'].mean(),\"std of val score\": cv_results['test_score'].std()}\n",
    "summary_df2.loc[len(summary_df2)] = new_row      \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test another solver and penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:    0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.228346586227417 seconds ---\n",
      "average score:  0.7365480407750467 std of score:  0.016820266758700964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    2.0s finished\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "\n",
    "logit1 = LogisticRegression(penalty='l1',solver='liblinear',max_iter=1000,random_state=12345,verbose=1)\n",
    "cv_results = cv_rskf(logit1,n_splits=10,n_repeats=10,seed=12345)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time() - start_time))     \n",
    "print(\"average score: \", cv_results['test_score'].mean(), \"std of score: \", cv_results['test_score'].std()) \n",
    "\n",
    "# insert to df\n",
    "new_row = {'penalty': logit1.get_params()['penalty'], 'solver': logit1.get_params()['solver'], \n",
    "                'average score': cv_results['test_score'].mean(),\"std of score\": cv_results['test_score'].std()}\n",
    "summary_df.loc[len(summary_df)] = new_row   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.8189518451690674 seconds ---\n",
      "average score:  0.736549809535266 std of score:  0.01679068582016181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    1.6s finished\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "\n",
    "logit2 = LogisticRegression(penalty='l2',solver='liblinear',max_iter=1000,random_state=12345,verbose=1)\n",
    "cv_results = cv_rskf(logit2,n_splits=10,n_repeats=10,seed=12345)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time() - start_time))     \n",
    "print(\"average score: \", cv_results['test_score'].mean(), \"std of score: \", cv_results['test_score'].std()) \n",
    "# insert to df\n",
    "new_row = {'penalty': logit2.get_params()['penalty'], 'solver': logit2.get_params()['solver'], \n",
    "                'average score': cv_results['test_score'].mean(),\"std of score\": cv_results['test_score'].std()}\n",
    "summary_df.loc[len(summary_df)] = new_row   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.8427543640136719 seconds ---\n",
      "average score:  0.7366449282916985 std of score:  0.016845227273181097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "\n",
    "logit3 = LogisticRegression(penalty=None,solver='newton-cholesky',max_iter=1000,random_state=12345,verbose=1)\n",
    "cv_results = cv_rskf(logit3,n_splits=10,n_repeats=10,seed=12345)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time() - start_time))     \n",
    "print(\"average score: \", cv_results['test_score'].mean(), \"std of score: \", cv_results['test_score'].std()) \n",
    "# insert to df\n",
    "new_row = {'penalty': logit3.get_params()['penalty'], 'solver': logit3.get_params()['solver'], \n",
    "                'average score': cv_results['test_score'].mean(),\"std of score\": cv_results['test_score'].std()}\n",
    "summary_df.loc[len(summary_df)] = new_row   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.9306094646453857 seconds ---\n",
      "average score:  0.7364076319553041 std of score:  0.016803309646989683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "\n",
    "logit4 = LogisticRegression(penalty='l2',solver='newton-cholesky',max_iter=1000,random_state=12345,verbose=1)\n",
    "cv_results = cv_rskf(logit4,n_splits=10,n_repeats=10,seed=12345)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time() - start_time))     \n",
    "print(\"average score: \", cv_results['test_score'].mean(), \"std of score: \", cv_results['test_score'].std())\n",
    "# insert to df\n",
    "new_row = {'penalty': logit4.get_params()['penalty'], 'solver': logit4.get_params()['solver'], \n",
    "                'average score': cv_results['test_score'].mean(),\"std of score\": cv_results['test_score'].std()}\n",
    "summary_df.loc[len(summary_df)] = new_row   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:    0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.2714762687683105 seconds ---\n",
      "average score:  0.736438496152835 std of score:  0.016775969535535683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    2.2s finished\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "\n",
    "logit5 = LogisticRegression(penalty='l2',solver='saga',max_iter=1000,random_state=12345,verbose=1)\n",
    "cv_results = cv_rskf(logit5,n_splits=10,n_repeats=10,seed=12345)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time() - start_time))     \n",
    "print(\"average score: \", cv_results['test_score'].mean(), \"std of score: \", cv_results['test_score'].std()) \n",
    "# insert to df\n",
    "new_row = {'penalty': logit5.get_params()['penalty'], 'solver': logit5.get_params()['solver'], \n",
    "                'average score': cv_results['test_score'].mean(),\"std of score\": cv_results['test_score'].std()}\n",
    "summary_df.loc[len(summary_df)] = new_row   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:    0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.1578879356384277 seconds ---\n",
      "average score:  0.736438496152835 std of score:  0.016775969535535683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    1.9s finished\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "\n",
    "logit6 = LogisticRegression(penalty='elasticnet',solver='saga',max_iter=1000,random_state=12345,verbose=1)\n",
    "cv_results = cv_rskf(logit5,n_splits=10,n_repeats=10,seed=12345)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time() - start_time))     \n",
    "print(\"average score: \", cv_results['test_score'].mean(), \"std of score: \", cv_results['test_score'].std()) \n",
    "# insert to df\n",
    "new_row = {'penalty': logit6.get_params()['penalty'], 'solver': logit6.get_params()['solver'], \n",
    "                'average score': cv_results['test_score'].mean(),\"std of score\": cv_results['test_score'].std()}\n",
    "summary_df.loc[len(summary_df)] = new_row   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.0087006092071533 seconds ---\n",
      "average score:  0.736438496152835 std of score:  0.016775969535535683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    1.8s finished\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "\n",
    "logit7 = LogisticRegression(penalty=None,solver='saga',max_iter=1000,random_state=12345,verbose=1)\n",
    "cv_results = cv_rskf(logit5,n_splits=10,n_repeats=10,seed=12345)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time() - start_time))     \n",
    "print(\"average score: \", cv_results['test_score'].mean(), \"std of score: \", cv_results['test_score'].std()) \n",
    "# insert to df\n",
    "new_row = {'penalty': logit7.get_params()['penalty'], 'solver': logit7.get_params()['solver'], \n",
    "                'average score': cv_results['test_score'].mean(),\"std of score\": cv_results['test_score'].std()}\n",
    "summary_df.loc[len(summary_df)] = new_row   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>average score</th>\n",
       "      <th>std of score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>0.7366449283</td>\n",
       "      <td>0.0168452273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.7365539231</td>\n",
       "      <td>0.0168197751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.7365498095</td>\n",
       "      <td>0.0167906858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.7365480408</td>\n",
       "      <td>0.0168202668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.7364384962</td>\n",
       "      <td>0.0167759695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.7364384962</td>\n",
       "      <td>0.0167759695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.7364384962</td>\n",
       "      <td>0.0167759695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>0.7364076320</td>\n",
       "      <td>0.0168033096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      penalty           solver  average score  std of score\n",
       "3        None  newton-cholesky   0.7366449283  0.0168452273\n",
       "0          l1             saga   0.7365539231  0.0168197751\n",
       "2          l2        liblinear   0.7365498095  0.0167906858\n",
       "1          l1        liblinear   0.7365480408  0.0168202668\n",
       "5          l2             saga   0.7364384962  0.0167759695\n",
       "6  elasticnet             saga   0.7364384962  0.0167759695\n",
       "7        None             saga   0.7364384962  0.0167759695\n",
       "4          l2  newton-cholesky   0.7364076320  0.0168033096"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.precision\", 10)\n",
    "summary_df.sort_values(ascending=False,by=\"average score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.sort_values(ascending=False,by=\"average score\").to_csv('./results/logit_metrics.csv', index=False,sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
